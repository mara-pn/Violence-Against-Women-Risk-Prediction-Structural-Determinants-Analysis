{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175a4983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    VAWG Dashboard Setup Script\n",
      "    ===========================\n",
      "\n",
      "    To run setup, use:\n",
      "\n",
      "    # Import your data and models\n",
      "    individual_df = pd.read_csv('path/to/individual_df.csv')\n",
      "    violence_df = pd.read_csv('path/to/violence_df.csv')\n",
      "    global_df = pd.read_csv('path/to/global_df.csv')\n",
      "    global_stats_df = pd.read_csv('path/to/global_stats.csv')\n",
      "\n",
      "    # Load your trained models\n",
      "    individual_model = joblib.load('path/to/individual_model.pkl')\n",
      "    violence_model = joblib.load('path/to/violence_model.pkl')\n",
      "    global_model = joblib.load('path/to/global_model.pkl')\n",
      "\n",
      "    # Run setup\n",
      "    complete_setup(\n",
      "        individual_df=individual_df,\n",
      "        violence_df=violence_df,\n",
      "        global_df=global_df,\n",
      "        global_stats_df=global_stats_df,\n",
      "        individual_model=individual_model,\n",
      "        violence_model=violence_model,\n",
      "        global_model=global_model\n",
      "    )\n",
      "\n",
      "    # Or run individual functions as needed:\n",
      "    # create_directories()\n",
      "    # save_models(individual_model, violence_model, global_model)\n",
      "    # prepare_individual_data(individual_df, individual_model)\n",
      "    # etc.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setup Script for VAWG Dashboard\n",
    "================================\n",
    "Run this once to save models and prepare data files\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ============================================\n",
    "# 1. CREATE DIRECTORY STRUCTURE\n",
    "# ============================================\n",
    "\n",
    "def create_directories():\n",
    "    \"\"\"Create necessary directories\"\"\"\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    os.makedirs('.streamlit', exist_ok=True)\n",
    "    print(\"✓ Created directories: data/, models/, .streamlit/\")\n",
    "\n",
    "# ============================================\n",
    "# 2. SAVE YOUR MODELS\n",
    "# ============================================\n",
    "\n",
    "def save_models(individual_model, violence_model, global_model):\n",
    "    \"\"\"\n",
    "    Save your trained models\n",
    "    \n",
    "    Usage:\n",
    "    ------\n",
    "    # After training your models:\n",
    "    save_models(\n",
    "        individual_model=xgb_individual,\n",
    "        violence_model=ensemble_violence,\n",
    "        global_model=ensemble_global\n",
    "    )\n",
    "    \"\"\"\n",
    "    joblib.dump(individual_model, 'models/individual_model.pkl')\n",
    "    joblib.dump(violence_model, 'models/violence_model.pkl')\n",
    "    joblib.dump(global_model, 'models/global_model.pkl')\n",
    "    \n",
    "    print(\"✓ Saved models:\")\n",
    "    print(\"  - models/individual_model.pkl\")\n",
    "    print(\"  - models/violence_model.pkl\")\n",
    "    print(\"  - models/global_model.pkl\")\n",
    "\n",
    "# ============================================\n",
    "# 3. PREPARE DATA FILES\n",
    "# ============================================\n",
    "\n",
    "def prepare_individual_data(df, model, save_path='data/individual_df.csv'):\n",
    "    \"\"\"\n",
    "    Prepare individual dataset with predictions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Your individual dataset with all engineered features\n",
    "    model : sklearn model\n",
    "        Your trained individual model\n",
    "    \"\"\"\n",
    "    # Add predictions if not already present\n",
    "    if 'predicted_violence' not in df.columns:\n",
    "        X = df.drop(columns=['violence'])\n",
    "        df['predicted_violence'] = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"✓ Saved {save_path}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "\n",
    "def prepare_violence_data(df, model, save_path='data/violence_df.csv'):\n",
    "    \"\"\"\n",
    "    Prepare violence/country dataset with predictions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Your violence dataset (50 countries)\n",
    "    model : sklearn model\n",
    "        Your trained violence model\n",
    "    \"\"\"\n",
    "    # Identify feature columns (exclude target and identifiers)\n",
    "    feature_cols = [\n",
    "        'structural_inequality_index',\n",
    "        'violence_exposure_index',\n",
    "        'general_danger_index',\n",
    "        'economic_empowerment_gap',\n",
    "        'inequality_attitudes_interaction',\n",
    "        'education_attitudes_interaction',\n",
    "        'legal_violence_interaction'\n",
    "    ]\n",
    "    \n",
    "    # Add predictions if not already present\n",
    "    if 'predicted_ipv' not in df.columns and model is not None:\n",
    "        X = df[feature_cols]\n",
    "        df['predicted_ipv'] = model.predict(X)\n",
    "    \n",
    "    # Also add predicted_violence column for consistency\n",
    "    if 'predicted_violence' not in df.columns:\n",
    "        # Violence exposure index is a good proxy\n",
    "        df['predicted_violence'] = df['violence_exposure_index']\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"✓ Saved {save_path}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "\n",
    "def prepare_global_data(df, model, save_path='data/global_df.csv'):\n",
    "    \"\"\"\n",
    "    Prepare global dataset with predictions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Your global dataset (195 countries)\n",
    "    model : sklearn model\n",
    "        Your trained global model\n",
    "    \"\"\"\n",
    "    # Identify feature columns\n",
    "    feature_cols = [col for col in df.columns \n",
    "                   if col not in ['country', 'ip_violence', 'predicted_ipv']]\n",
    "    \n",
    "    # Add predictions if not already present\n",
    "    if 'predicted_ipv' not in df.columns and model is not None:\n",
    "        X = df[feature_cols]\n",
    "        df['predicted_ipv'] = model.predict(X)\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"✓ Saved {save_path}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "\n",
    "def prepare_global_stats(df, save_path='data/global_stats.csv'):\n",
    "    \"\"\"\n",
    "    Prepare global stats (additional context)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Your global_stats dataset with columns like income_category, gii, etc.\n",
    "    \"\"\"\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"✓ Saved {save_path}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "\n",
    "# ============================================\n",
    "# 4. CREATE STREAMLIT SECRETS FILE\n",
    "# ============================================\n",
    "\n",
    "def create_secrets_template():\n",
    "    \"\"\"Create template for Streamlit secrets\"\"\"\n",
    "    secrets_content = '''# Streamlit Secrets\n",
    "# Add your OpenAI API key here\n",
    "# DO NOT commit this file to Git!\n",
    "\n",
    "OPENAI_API_KEY = \"sk-your-key-here\"\n",
    "'''\n",
    "    \n",
    "    with open('.streamlit/secrets.toml', 'w') as f:\n",
    "        f.write(secrets_content)\n",
    "    \n",
    "    print(\"Created .streamlit/secrets.toml\")\n",
    "    print(\"Remember to add your actual API key!\")\n",
    "\n",
    "# ============================================\n",
    "# 5. CREATE .GITIGNORE\n",
    "# ============================================\n",
    "\n",
    "def create_gitignore():\n",
    "    \"\"\"Create .gitignore to protect secrets\"\"\"\n",
    "    gitignore_content = '''# Streamlit secrets\n",
    ".streamlit/secrets.toml\n",
    "\n",
    "# Models (large files)\n",
    "models/*.pkl\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.py[cod]\n",
    "*$py.class\n",
    "*.so\n",
    ".Python\n",
    "env/\n",
    "venv/\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "\n",
    "# OS\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "'''\n",
    "    \n",
    "    with open('.gitignore', 'w') as f:\n",
    "        f.write(gitignore_content)\n",
    "    \n",
    "    print(\"✓ Created .gitignore\")\n",
    "\n",
    "# ============================================\n",
    "# 6. CREATE REQUIREMENTS.TXT\n",
    "# ============================================\n",
    "\n",
    "def create_requirements():\n",
    "    \"\"\"Create requirements.txt\"\"\"\n",
    "    requirements = '''streamlit==1.29.0\n",
    "pandas==2.1.4\n",
    "numpy==1.26.2\n",
    "plotly==5.18.0\n",
    "scikit-learn==1.3.2\n",
    "openai==1.6.1\n",
    "joblib==1.3.2\n",
    "xgboost==2.0.3\n",
    "'''\n",
    "    \n",
    "    with open('requirements.txt', 'w') as f:\n",
    "        f.write(requirements)\n",
    "    \n",
    "    print(\"✓ Created requirements.txt\")\n",
    "\n",
    "# ============================================\n",
    "# 7. COMPLETE SETUP\n",
    "# ============================================\n",
    "\n",
    "def complete_setup(\n",
    "    individual_df,\n",
    "    violence_df,\n",
    "    global_df,\n",
    "    global_stats_df,\n",
    "    individual_model,\n",
    "    violence_model,\n",
    "    global_model\n",
    "):\n",
    "    \"\"\"\n",
    "    Run complete setup\n",
    "    \n",
    "    Usage:\n",
    "    ------\n",
    "    complete_setup(\n",
    "        individual_df=your_individual_df,\n",
    "        violence_df=your_violence_df,\n",
    "        global_df=your_global_df,\n",
    "        global_stats_df=your_global_stats_df,\n",
    "        individual_model=your_individual_model,\n",
    "        violence_model=your_violence_model,\n",
    "        global_model=your_global_model\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"VAWG DASHBOARD SETUP\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    # Create directories\n",
    "    create_directories()\n",
    "    print()\n",
    "    \n",
    "    # Save models\n",
    "    print(\"Saving models...\")\n",
    "    save_models(individual_model, violence_model, global_model)\n",
    "    print()\n",
    "    \n",
    "    # Save data\n",
    "    print(\"Preparing data files...\")\n",
    "    prepare_individual_data(individual_df, individual_model)\n",
    "    prepare_violence_data(violence_df, violence_model)\n",
    "    prepare_global_data(global_df, global_model)\n",
    "    prepare_global_stats(global_stats_df)\n",
    "    print()\n",
    "    \n",
    "    # Create config files\n",
    "    print(\"Creating configuration files...\")\n",
    "    create_secrets_template()\n",
    "    create_gitignore()\n",
    "    create_requirements()\n",
    "    print()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"SETUP COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    print(\"Next steps:\")\n",
    "    print(\"1. Add your OpenAI API key to .streamlit/secrets.toml\")\n",
    "    print(\"2. Run: streamlit run app.py\")\n",
    "    print(\"3. Test all three tools\")\n",
    "    print()\n",
    "    print(\"For deployment:\")\n",
    "    print(\"1. Push to GitHub (make sure .gitignore is working)\")\n",
    "    print(\"2. Deploy on Streamlit Cloud\")\n",
    "    print(\"3. Add API key in Streamlit Cloud settings\")\n",
    "    print()\n",
    "\n",
    "# ============================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\"\"\n",
    "    VAWG Dashboard Setup Script\n",
    "    ===========================\n",
    "    \n",
    "    To run setup, use:\n",
    "    \n",
    "    # Import your data and models\n",
    "    individual_df = pd.read_csv('path/to/individual_df.csv')\n",
    "    violence_df = pd.read_csv('path/to/violence_df.csv')\n",
    "    global_df = pd.read_csv('path/to/global_df.csv')\n",
    "    global_stats_df = pd.read_csv('path/to/global_stats.csv')\n",
    "    \n",
    "    # Load your trained models\n",
    "    individual_model = joblib.load('path/to/individual_model.pkl')\n",
    "    violence_model = joblib.load('path/to/violence_model.pkl')\n",
    "    global_model = joblib.load('path/to/global_model.pkl')\n",
    "    \n",
    "    # Run setup\n",
    "    complete_setup(\n",
    "        individual_df=individual_df,\n",
    "        violence_df=violence_df,\n",
    "        global_df=global_df,\n",
    "        global_stats_df=global_stats_df,\n",
    "        individual_model=individual_model,\n",
    "        violence_model=violence_model,\n",
    "        global_model=global_model\n",
    "    )\n",
    "    \n",
    "    # Or run individual functions as needed:\n",
    "    # create_directories()\n",
    "    # save_models(individual_model, violence_model, global_model)\n",
    "    # prepare_individual_data(individual_df, individual_model)\n",
    "    # etc.\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ironhack)",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
