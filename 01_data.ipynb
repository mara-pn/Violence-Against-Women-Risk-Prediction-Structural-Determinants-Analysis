{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37353121",
   "metadata": {},
   "source": [
    "# Data Loading \n",
    "\n",
    "This notebook serves to ingest all raw datasets, to clean them, harmonize & merge them if needed and save the cleaned CSVs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918b2f4",
   "metadata": {},
   "source": [
    "## 0. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "9c9ec393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "import zipfile\n",
    "import glob\n",
    "import shutil\n",
    "import re\n",
    "import sys\n",
    "#!{sys.executable} -m pip install pycountry\n",
    "import pycountry\n",
    "#!{sys.executable} -m pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b0c9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path \n",
    "DATA_RAW = os.path.join(\"..\", \"data\", \"raw\")\n",
    "DATA_CLEAN = os.path.join(\"..\", \"data\", \"clean\")\n",
    "DATA_PROCESSED = os.path.join(\"..\", \"data\", \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d207a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb56610",
   "metadata": {},
   "source": [
    "## 1. File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca02790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path \n",
    "BASE_DIR = Path(r\"C:/Users/black/Documents/Ironhack/final_project\")\n",
    "RAW_DIR = BASE_DIR / \"data\" / \"raw\"\n",
    "CLEAN_DIR = BASE_DIR / \"data\" / \"clean\"\n",
    "PROCESSED_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6baa2c",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2f717",
   "metadata": {},
   "source": [
    "### 2.1 Loading Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af180d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kagglehub_dataset(dataset_name, download_dir):\n",
    "    \"\"\" Download & save dataset from KaggleHub.\"\"\"\n",
    "    try:\n",
    "        print(f\"Downloading dataset: {dataset_name}\")\n",
    "        path = kagglehub.dataset_download(dataset_name)\n",
    "        print(\"Dataset downloaded to:\", path)\n",
    "\n",
    "        # Move downloaded files into your /data/raw folder\n",
    "        dest = download_dir / dataset_name.replace(\"/\", \"_\")\n",
    "        dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Copy all downloaded files to the raw directory\n",
    "        source_path = Path(path)\n",
    "        for file in source_path.rglob(\"*\"):  \n",
    "            if file.is_file():\n",
    "                relative_path = file.relative_to(source_path)\n",
    "                new_file = dest / relative_path.name  \n",
    "                \n",
    "                if not new_file.exists():  \n",
    "                    print(f\"Copying: {file.name}\")\n",
    "                    shutil.copy2(file, new_file)\n",
    "\n",
    "        print(f\"Files moved to: {dest}\")\n",
    "        return dest\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading dataset {dataset_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def unzip_files_in_folder(folder_path):\n",
    "    \"\"\"Extract all ZIP files inside a folder.\"\"\"\n",
    "    zip_files = list(folder_path.glob(\"*.zip\"))\n",
    "\n",
    "    if not zip_files:\n",
    "        return\n",
    "\n",
    "    for z in zip_files:\n",
    "        print(f\"Extracting: {z.name}\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(z, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(folder_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error unzipping {z.name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_csv_from_folder(folder_path):\n",
    "    \"\"\"Find and load the first CSV file in the folder with encoding handling.\"\"\"\n",
    "    csv_files = list(folder_path.glob(\"*.csv\"))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in: {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    if len(csv_files) > 1:\n",
    "        print(f\"Multiple CSV files found, loading the first one:\\n{csv_files}\")\n",
    "\n",
    "    file_to_load = csv_files[0]\n",
    "    print(f\"Loading CSV: {file_to_load.name}\")\n",
    "\n",
    "    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            print(f\"  Trying {encoding}...\")\n",
    "            df = pd.read_csv(file_to_load, encoding=encoding)\n",
    "            print(f\"Success with {encoding}!\")\n",
    "            return df\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"  All encodings failed. Loading with error='ignore'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_to_load, encoding='utf-8', encoding_errors='ignore')\n",
    "        print(\"Loaded (some characters may be missing)\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Failed completely: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f3341",
   "metadata": {},
   "source": [
    "### 2.2 Standardization + Quick Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "900dadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df):\n",
    "    \"\"\"Convert all column names to snake_case.\"\"\"\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")\n",
    "        .str.replace(\"-\", \"_\")\n",
    "        .str.replace(r\"[^a-zA-Z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecdb9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_clean(df):\n",
    "    \"\"\"Light cleaning: strip whitespace, unify types.\"\"\"\n",
    "    for col in df.select_dtypes(include=\"object\"):\n",
    "        df[col] = df[col].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, path):\n",
    "    \"\"\"Save DataFrame cleanly.\"\"\"\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Saved to: {path}\")\n",
    "\n",
    "\n",
    "def load_kagglehub_csv(dataset_name, raw_dir, auto_save=True):\n",
    "    \"\"\"\n",
    "    High-level helper:\n",
    "    1. Download dataset from KaggleHub\n",
    "    2. Load first CSV found\n",
    "    3. Standardize columns & basic cleaning\n",
    "    4. Auto-save cleaned version to RAW_DIR\n",
    "    \"\"\"\n",
    "    # Create a clean filename for saving\n",
    "    clean_filename = dataset_name.replace(\"/\", \"_\") + \"_cleaned.csv\"\n",
    "    save_path = raw_dir / clean_filename\n",
    "    \n",
    "    # Check if already exists\n",
    "    if save_path.exists():\n",
    "        print(f\"Loading existing cleaned file: {clean_filename}\")\n",
    "        df = pd.read_csv(save_path)\n",
    "        return df\n",
    "    \n",
    "    # Otherwise, download and process\n",
    "    folder = download_kagglehub_dataset(dataset_name, raw_dir)\n",
    "    if folder is None:\n",
    "        return None\n",
    "    \n",
    "    unzip_files_in_folder(folder)\n",
    "\n",
    "    df = load_csv_from_folder(folder)\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    df = standardize_columns(df)\n",
    "    df = quick_clean(df)\n",
    "    \n",
    "    # Auto-save the cleaned version\n",
    "    if auto_save:\n",
    "        save_df(df, save_path, f\"Saved cleaned data: {clean_filename}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e707c8",
   "metadata": {},
   "source": [
    "### 2.3 Loading + Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "87e7840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kagglehub_dataset(dataset_name, download_dir):\n",
    "    \"\"\" Download & save dataset from KaggleHub.\"\"\"\n",
    "    try:\n",
    "        print(f\"Downloading dataset: {dataset_name}\")\n",
    "        path = kagglehub.dataset_download(dataset_name)\n",
    "        print(\"Dataset downloaded to:\", path)\n",
    "\n",
    "        # Move downloaded files into your /data/raw folder\n",
    "        dest = download_dir / dataset_name.replace(\"/\", \"_\")\n",
    "        dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Copy all downloaded files to the raw directory\n",
    "        source_path = Path(path)\n",
    "        for file in source_path.rglob(\"*\"):  \n",
    "            if file.is_file():\n",
    "                relative_path = file.relative_to(source_path)\n",
    "                new_file = dest / relative_path.name  \n",
    "                \n",
    "                if not new_file.exists():  \n",
    "                    print(f\"Copying: {file.name}\")\n",
    "                    shutil.copy2(file, new_file)\n",
    "\n",
    "        print(f\"Files moved to: {dest}\")\n",
    "        return dest\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading dataset {dataset_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def unzip_files_in_folder(folder_path):\n",
    "    \"\"\"Extract all ZIP files inside a folder.\"\"\"\n",
    "    zip_files = list(folder_path.glob(\"*.zip\"))\n",
    "\n",
    "    if not zip_files:\n",
    "        return\n",
    "\n",
    "    for z in zip_files:\n",
    "        print(f\"Extracting: {z.name}\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(z, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(folder_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error unzipping {z.name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_csv_from_folder(folder_path):\n",
    "    \"\"\"Find and load the first CSV file in the folder with encoding handling.\"\"\"\n",
    "    csv_files = list(folder_path.glob(\"*.csv\"))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in: {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    if len(csv_files) > 1:\n",
    "        print(f\"Multiple CSV files found, loading the first one:\\n{csv_files}\")\n",
    "\n",
    "    file_to_load = csv_files[0]\n",
    "    print(f\"Loading CSV: {file_to_load.name}\")\n",
    "\n",
    "    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            print(f\"  Trying {encoding}...\")\n",
    "            df = pd.read_csv(file_to_load, encoding=encoding)\n",
    "            print(f\"Success with {encoding}!\")\n",
    "            return df\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"  All encodings failed. Loading with error='ignore'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_to_load, encoding='utf-8', encoding_errors='ignore')\n",
    "        print(\"Loaded (some characters may be missing)\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Failed completely: {e}\")\n",
    "        return None\n",
    "def standardize_columns(df):\n",
    "    \"\"\"Convert all column names to snake_case.\"\"\"\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")\n",
    "        .str.replace(\"-\", \"_\")\n",
    "        .str.replace(r\"[^a-zA-Z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "def quick_clean(df):\n",
    "    \"\"\"Light cleaning: strip whitespace, unify types.\"\"\"\n",
    "    for col in df.select_dtypes(include=\"object\"):\n",
    "        df[col] = df[col].str.strip()\n",
    "    return df\n",
    "def load_kagglehub_csv(dataset_name, raw_dir):\n",
    "    \"\"\"\n",
    "    High-level helper:\n",
    "    1. Download dataset from KaggleHub\n",
    "    2. Load first CSV found\n",
    "    3. Standardize columns & basic cleaning\n",
    "    \"\"\"\n",
    "    folder = download_kagglehub_dataset(dataset_name, raw_dir)\n",
    "    if folder is None:\n",
    "        return None\n",
    "    \n",
    "    unzip_files_in_folder(folder)\n",
    "\n",
    "    df = load_csv_from_folder(folder)\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    df = standardize_columns(df)\n",
    "    df = quick_clean(df)\n",
    "    return df\n",
    "def save_df(df, path):\n",
    "    \"\"\"Save DataFrame cleanly.\"\"\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Saved to: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dc6f2",
   "metadata": {},
   "source": [
    "### 2.4 ISO Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "4fe7571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iso_code(country_name, method='alpha_3'):\n",
    "    \"\"\"\n",
    "    Get ISO code for a country name using pycountry.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    country_name : str\n",
    "        The country name to look up\n",
    "    method : str\n",
    "        'alpha_2' for 2-letter codes (US, GB)\n",
    "        'alpha_3' for 3-letter codes (USA, GBR) - default\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str or None : ISO code if found, None otherwise\n",
    "    \"\"\"\n",
    "    if pd.isna(country_name) or country_name == '':\n",
    "        return None\n",
    "    \n",
    "    country_name = str(country_name).strip()\n",
    "    \n",
    "    # Direct lookup by name\n",
    "    try:\n",
    "        country = pycountry.countries.get(name=country_name)\n",
    "        if country:\n",
    "            return country.alpha_3 if method == 'alpha_3' else country.alpha_2\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try official name\n",
    "    try:\n",
    "        country = pycountry.countries.get(official_name=country_name)\n",
    "        if country:\n",
    "            return country.alpha_3 if method == 'alpha_3' else country.alpha_2\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fuzzy matching for close matches\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for country in pycountry.countries:\n",
    "        # Check name\n",
    "        score = fuzz.ratio(country_name.lower(), country.name.lower())\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = country\n",
    "        \n",
    "        # Check common_name if exists\n",
    "        if hasattr(country, 'common_name'):\n",
    "            score = fuzz.ratio(country_name.lower(), country.common_name.lower())\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = country\n",
    "        \n",
    "        # Check official_name if exists\n",
    "        if hasattr(country, 'official_name'):\n",
    "            score = fuzz.ratio(country_name.lower(), country.official_name.lower())\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = country\n",
    "    \n",
    "    # Only return if confidence is high enough (>85% match)\n",
    "    if best_score >= 85 and best_match:\n",
    "        return best_match.alpha_3 if method == 'alpha_3' else best_match.alpha_2\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def create_country_mapping():\n",
    "    \"\"\"\n",
    "    Create a manual mapping for countries that pycountry struggles with.\n",
    "    This handles common variations and special cases.\n",
    "    \"\"\"\n",
    "    manual_mapping = {\n",
    "        # Common variations\n",
    "        'United States': 'USA',\n",
    "        'USA': 'USA',\n",
    "        'US': 'USA',\n",
    "        'United States of America': 'USA',\n",
    "        'UK': 'GBR',\n",
    "        'United Kingdom': 'GBR',\n",
    "        'England': 'GBR',\n",
    "        'Great Britain': 'GBR',\n",
    "        'Russia': 'RUS',\n",
    "        'Russian Federation': 'RUS',\n",
    "        'South Korea': 'KOR',\n",
    "        'Korea, Republic of': 'KOR',\n",
    "        'North Korea': 'PRK',\n",
    "        \"Korea, Democratic People's Republic of\": 'PRK',\n",
    "        'Vietnam': 'VNM',\n",
    "        'Viet Nam': 'VNM',\n",
    "        'Syria': 'SYR',\n",
    "        'Syrian Arab Republic': 'SYR',\n",
    "        'Iran': 'IRN',\n",
    "        'Iran, Islamic Republic of': 'IRN',\n",
    "        'Venezuela': 'VEN',\n",
    "        'Venezuela, Bolivarian Republic of': 'VEN',\n",
    "        'Bolivia': 'BOL',\n",
    "        'Bolivia, Plurinational State of': 'BOL',\n",
    "        'Tanzania': 'TZA',\n",
    "        'Tanzania, United Republic of': 'TZA',\n",
    "        'Moldova': 'MDA',\n",
    "        'Moldova, Republic of': 'MDA',\n",
    "        'Laos': 'LAO',\n",
    "        \"Lao People's Democratic Republic\": 'LAO',\n",
    "        'Palestine': 'PSE',\n",
    "        'Palestinian Territory': 'PSE',\n",
    "        'Palestinian Territories': 'PSE',\n",
    "        'State of Palestine': 'PSE',\n",
    "        'Czechia': 'CZE',\n",
    "        'Czech Republic': 'CZE',\n",
    "        'Turkey': 'TUR',\n",
    "        'Türkiye': 'TUR',\n",
    "        'Cape Verde': 'CPV',\n",
    "        'Cabo Verde': 'CPV',\n",
    "        'Congo': 'COG',\n",
    "        'Republic of the Congo': 'COG',\n",
    "        'Congo, Republic of the': 'COG',\n",
    "        'Democratic Republic of the Congo': 'COD',\n",
    "        'Congo, Democratic Republic of the': 'COD',\n",
    "        'DR Congo': 'COD',\n",
    "        'DRC': 'COD',\n",
    "        'Ivory Coast': 'CIV',\n",
    "        \"Côte d'Ivoire\": 'CIV',\n",
    "        'Cote d\\'Ivoire': 'CIV',\n",
    "        'Brunei': 'BRN',\n",
    "        'Brunei Darussalam': 'BRN',\n",
    "        'Micronesia': 'FSM',\n",
    "        'Micronesia, Federated States of': 'FSM',\n",
    "        'Macedonia': 'MKD',\n",
    "        'North Macedonia': 'MKD',\n",
    "        'The former Yugoslav Republic of Macedonia': 'MKD',\n",
    "        'Eswatini': 'SWZ',\n",
    "        'Swaziland': 'SWZ',\n",
    "        'East Timor': 'TLS',\n",
    "        'Timor-Leste': 'TLS',\n",
    "        'Burma': 'MMR',\n",
    "        'Myanmar': 'MMR',\n",
    "        'Gambia': 'GMB',\n",
    "        'The Gambia': 'GMB',\n",
    "        'Bahamas': 'BHS',\n",
    "        'The Bahamas': 'BHS',\n",
    "        'Congo Democratic Republic': 'COD',\n",
    "        'Congo, Dem. Rep.': 'COD',\n",
    "        'Bahamas, The': 'BHS',  \n",
    "        'Congo, Rep.': 'COG',\n",
    "        'Egypt, Arab Rep.': 'EGY',\n",
    "        'Gambia, The': 'GMB',\n",
    "        'Hong Kong SAR, China': 'HKG',\n",
    "        'Hong Kong, China': 'HKG',\n",
    "        'Macau, China': 'MAC',\n",
    "        'Taiwan, China': 'TWN',\n",
    "        'Iran, Islamic Rep.': 'IRN',\n",
    "        'Korea, Rep.': 'KOR',\n",
    "        'Lao PDR': 'LAO',\n",
    "        'Venezuela, RB': 'VEN',\n",
    "        'Yemen, Rep.': 'YEM',\n",
    "        'Channel Islands': 'GBR',\n",
    "        'United States Virgin Islands': 'VIR',\n",
    "        'Netherlands (Kingdom of the)': 'NLD',\n",
    "    }\n",
    "    return manual_mapping\n",
    "\n",
    "\n",
    "def add_iso_codes(df, country_col='country', method='alpha_3', new_col_name='iso'):\n",
    "    \"\"\"\n",
    "    Add ISO codes to a DataFrame with a country column.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing country names\n",
    "    country_col : str\n",
    "        Name of the column containing country names (default: 'country')\n",
    "    method : str\n",
    "        'alpha_2' for 2-letter codes or 'alpha_3' for 3-letter codes\n",
    "    new_col_name : str\n",
    "        Name for the new ISO code column (default: 'iso')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : DataFrame with new ISO code column\n",
    "    dict : Dictionary of unmatched countries\n",
    "    \"\"\"\n",
    "    if country_col not in df.columns:\n",
    "        print(f\"Warning: Column '{country_col}' not found in DataFrame\")\n",
    "        return df, {}\n",
    "    \n",
    "    df = df.copy()\n",
    "    manual_mapping = create_country_mapping()\n",
    "    \n",
    "    # Apply manual mapping first, then pycountry lookup\n",
    "    def get_code(country_name):\n",
    "        if pd.isna(country_name):\n",
    "            return None\n",
    "        \n",
    "        country_name_clean = str(country_name).strip()\n",
    "        \n",
    "        # Check manual mapping first\n",
    "        if country_name_clean in manual_mapping:\n",
    "            return manual_mapping[country_name_clean]\n",
    "        \n",
    "        # Otherwise use pycountry\n",
    "        return get_iso_code(country_name_clean, method=method)\n",
    "    \n",
    "    # Add ISO codes\n",
    "    df[new_col_name] = df[country_col].apply(get_code)\n",
    "    \n",
    "    # Identify unmatched countries\n",
    "    unmatched = df[df[new_col_name].isna()][country_col].unique()\n",
    "    unmatched_dict = {country: None for country in unmatched if pd.notna(country)}\n",
    "    \n",
    "    if unmatched_dict:\n",
    "        print(f\"\\nWarning: {len(unmatched_dict)} countries could not be matched:\")\n",
    "        for country in sorted(unmatched_dict.keys()):\n",
    "            print(f\"  - {country}\")\n",
    "        print(\"\\nConsider adding these to the manual mapping.\")\n",
    "    else:\n",
    "        print(f\"All countries successfully matched!\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    total = len(df)\n",
    "    matched = df[new_col_name].notna().sum()\n",
    "    print(f\"\\nMatching Summary:\")\n",
    "    print(f\"   Total rows: {total}\")\n",
    "    print(f\"   Matched: {matched} ({matched/total*100:.1f}%)\")\n",
    "    print(f\"   Unmatched: {total - matched} ({(total-matched)/total*100:.1f}%)\")\n",
    "    \n",
    "    return df, unmatched_dict\n",
    "\n",
    "\n",
    "def standardize_all_countries(datasets_dict):\n",
    "    \"\"\"\n",
    "    Add ISO codes to all datasets in a dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    datasets_dict : dict\n",
    "        Dictionary where keys are dataset names and values are DataFrames\n",
    "        Example: {'domestic': dv_df_pro, 'vawg': vawg_df_pro, ...}\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with updated DataFrames\n",
    "    dict : Dictionary of all unmatched countries by dataset\n",
    "    \"\"\"\n",
    "    updated_datasets = {}\n",
    "    all_unmatched = {}\n",
    "    \n",
    "    # Define which column contains country names for each dataset\n",
    "    country_columns = {\n",
    "        'domestic': None,  \n",
    "        'vawg': 'country',\n",
    "        'freedom': 'country',\n",
    "        'danger': 'country',\n",
    "        'gdp': 'country',  \n",
    "        'wage_gap': None,  \n",
    "        'unemployment': 'country',\n",
    "        'gii': 'country',\n",
    "        'legal': 'country',\n",
    "        'partner_violence': 'country',\n",
    "        'eq_laws': 'continent', \n",
    "    }\n",
    "    \n",
    "    for dataset_name, df in datasets_dict.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {dataset_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        country_col = country_columns.get(dataset_name)\n",
    "        \n",
    "        # Skip if no country column\n",
    "        if country_col is None:\n",
    "            print(f\"Skipping (no country column or already has ISO)\")\n",
    "            updated_datasets[dataset_name] = df\n",
    "            continue\n",
    "        \n",
    "        # Skip if already has ISO column\n",
    "        if 'iso' in df.columns:\n",
    "            print(f\"Already has 'iso' column\")\n",
    "            updated_datasets[dataset_name] = df\n",
    "            continue\n",
    "        \n",
    "        # Add ISO codes\n",
    "        updated_df, unmatched = add_iso_codes(\n",
    "            df, \n",
    "            country_col=country_col,\n",
    "            method='alpha_3',\n",
    "            new_col_name='iso'\n",
    "        )\n",
    "        \n",
    "        updated_datasets[dataset_name] = updated_df\n",
    "        if unmatched:\n",
    "            all_unmatched[dataset_name] = unmatched\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    if all_unmatched:\n",
    "        print(\"\\nDatasets with unmatched countries:\")\n",
    "        for dataset, countries in all_unmatched.items():\n",
    "            print(f\"\\n  {dataset.upper()}: {len(countries)} unmatched\")\n",
    "            for country in sorted(countries.keys())[:11]:  \n",
    "                print(f\"    - {country}\")\n",
    "            if len(countries) > 11:\n",
    "                print(f\"    ... and {len(countries) - 11} more\")\n",
    "    else:\n",
    "        print(\"\\nAll countries matched across all datasets!\")\n",
    "    \n",
    "    return updated_datasets, all_unmatched\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90afddcf",
   "metadata": {},
   "source": [
    "## 2. Load all Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498db37",
   "metadata": {},
   "source": [
    "### 2.1 Load & Quick Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14f15207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: fahmidachowdhury/domestic-violence-against-women\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\fahmidachowdhury\\domestic-violence-against-women\\versions\\1\n",
      "Copying: Domestic violence.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\fahmidachowdhury_domestic-violence-against-women\n",
      "Loading CSV: Domestic violence.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: fahmidachowdhury_domestic-violence-against-women_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "dv_df_clean = load_kagglehub_csv(\"fahmidachowdhury/domestic-violence-against-women\", CLEAN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "677feab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: whenamancodes/violence-against-women-girls\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\whenamancodes\\violence-against-women-girls\\versions\\1\n",
      "Copying: Violence Against Women  Girls Data.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\whenamancodes_violence-against-women-girls\n",
      "Loading CSV: Violence Against Women  Girls Data.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: whenamancodes_violence-against-women-girls_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "vawg_df_clean = load_kagglehub_csv(\"whenamancodes/violence-against-women-girls\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e479fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing cleaned file: gsutters_the-human-freedom-index_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "hfi_df_clean = load_kagglehub_csv(\"gsutters/the-human-freedom-index\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd0b4ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: arpitsinghaiml/most-dangerous-countries-for-women-2024\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\arpitsinghaiml\\most-dangerous-countries-for-women-2024\\versions\\1\n",
      "Copying: most-dangerous-countries-for-women-2024.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\arpitsinghaiml_most-dangerous-countries-for-women-2024\n",
      "Loading CSV: most-dangerous-countries-for-women-2024.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: arpitsinghaiml_most-dangerous-countries-for-women-2024_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "mdc_df_clean = load_kagglehub_csv(\"arpitsinghaiml/most-dangerous-countries-for-women-2024\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba3bfc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: zgrcemta/world-gdpgdp-gdp-per-capita-and-annual-growths\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\zgrcemta\\world-gdpgdp-gdp-per-capita-and-annual-growths\\versions\\2\n",
      "Copying: gdp.csv\n",
      "Copying: gdp_growth.csv\n",
      "Copying: gdp_per_capita.csv\n",
      "Copying: gdp_per_capita_growth.csv\n",
      "Copying: gdp_ppp.csv\n",
      "Copying: gdp_ppp_per_capita.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\zgrcemta_world-gdpgdp-gdp-per-capita-and-annual-growths\n",
      "Multiple CSV files found, loading the first one:\n",
      "[WindowsPath('C:/Users/black/Documents/Ironhack/final_project/data/clean/zgrcemta_world-gdpgdp-gdp-per-capita-and-annual-growths/gdp.csv'), WindowsPath('C:/Users/black/Documents/Ironhack/final_project/data/clean/zgrcemta_world-gdpgdp-gdp-per-capita-and-annual-growths/gdp_growth.csv'), WindowsPath('C:/Users/black/Documents/Ironhack/final_project/data/clean/zgrcemta_world-gdpgdp-gdp-per-capita-and-annual-growths/gdp_per_capita.csv'), WindowsPath('C:/Users/black/Documents/Ironhack/final_project/data/clean/zgrcemta_world-gdpgdp-gdp-per-capita-and-annual-growths/gdp_per_capita_growth.csv'), WindowsPath('C:/Users/black/Documents/Ironhack/final_project/data/clean/zgrcemta_world-gdpgdp-gdp-per-capita-and-annual-growths/gdp_ppp.csv'), WindowsPath('C:/Users/black/Documents/Ironhack/final_project/data/clean/zgrcemta_world-gdpgdp-gdp-per-capita-and-annual-growths/gdp_ppp_per_capita.csv')]\n",
      "Loading CSV: gdp.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: zgrcemta_world-gdpgdp-gdp-per-capita-and-annual-growths_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "gdp_df_clean = load_kagglehub_csv(\"zgrcemta/world-gdpgdp-gdp-per-capita-and-annual-growths\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cbd05198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: mpwolke/cusersmarildownloadsgapcsv\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\mpwolke\\cusersmarildownloadsgapcsv\\versions\\1\n",
      "Copying: gap.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\mpwolke_cusersmarildownloadsgapcsv\n",
      "Loading CSV: gap.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: mpwolke_cusersmarildownloadsgapcsv_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "gwg_df_clean = load_kagglehub_csv(\"mpwolke/cusersmarildownloadsgapcsv\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "35e62e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: sazidthe1/global-unemployment-data\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\sazidthe1\\global-unemployment-data\\versions\\1\n",
      "Copying: global_unemployment_data.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\sazidthe1_global-unemployment-data\n",
      "Loading CSV: global_unemployment_data.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: sazidthe1_global-unemployment-data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "gud_df_clean = load_kagglehub_csv(\"sazidthe1/global-unemployment-data\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb290798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: nelgiriyewithana/world-educational-data\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\nelgiriyewithana\\world-educational-data\\versions\\1\n",
      "Copying: Global_Education.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\nelgiriyewithana_world-educational-data\n",
      "Loading CSV: Global_Education.csv\n",
      "  Trying utf-8...\n",
      "  Trying latin-1...\n",
      "Success with latin-1!\n",
      "Saved cleaned data: nelgiriyewithana_world-educational-data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "wed_df_clean = load_kagglehub_csv(\"nelgiriyewithana/world-educational-data\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cd122178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: gianinamariapetrascu/gender-inequality-index\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\gianinamariapetrascu\\gender-inequality-index\\versions\\2\n",
      "Copying: Gender_Inequality_Index.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\gianinamariapetrascu_gender-inequality-index\n",
      "Loading CSV: Gender_Inequality_Index.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: gianinamariapetrascu_gender-inequality-index_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "gii_df_clean = load_kagglehub_csv(\"gianinamariapetrascu/gender-inequality-index\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2dd1e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: willianoliveiragibin/legal-frameworks\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\willianoliveiragibin\\legal-frameworks\\versions\\1\n",
      "Copying: legal-frameworks-gender-equality-within-marriage-and-family new.csv\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\willianoliveiragibin_legal-frameworks\n",
      "Loading CSV: legal-frameworks-gender-equality-within-marriage-and-family new.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: willianoliveiragibin_legal-frameworks_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "lf_df_clean = load_kagglehub_csv(\"willianoliveiragibin/legal-frameworks\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "78c6b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip_df_raw = pd.read_csv(r\"data\\raw\\physical_sexual_abuse_current_or_former_partner.csv\")\n",
    "aip_df_clean = quick_clean(aip_df_raw)\n",
    "aip_df_clean = standardize_columns(aip_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c36a393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: shreyasur965/global-gender-equality-in-business-laws1970-2023\n",
      "Dataset downloaded to: C:\\Users\\black\\.cache\\kagglehub\\datasets\\shreyasur965\\global-gender-equality-in-business-laws1970-2023\\versions\\2\n",
      "Copying: women-rights.csv\n",
      "Copying: women_rights_column_descriptors.txt\n",
      "Files moved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\clean\\shreyasur965_global-gender-equality-in-business-laws1970-2023\n",
      "Loading CSV: women-rights.csv\n",
      "  Trying utf-8...\n",
      "Success with utf-8!\n",
      "Saved cleaned data: shreyasur965_global-gender-equality-in-business-laws1970-2023_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "gel_df_clean = load_kagglehub_csv(\"shreyasur965/global-gender-equality-in-business-laws1970-2023\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aacf0b3",
   "metadata": {},
   "source": [
    "### 2.2 Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64912ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DOMESTIC ---\n",
      "Shape: (347, 7)\n",
      "Columns: ['sl_no', 'age', 'education', 'employment', 'income', 'marital_status', 'violence']\n",
      "Missing values: 0\n",
      "\n",
      "--- VAWG ---\n",
      "Shape: (12600, 8)\n",
      "Columns: ['recordid', 'country', 'gender', 'demographics_question', 'demographics_response', 'question', 'survey_year', 'value']\n",
      "Missing values: 1413\n",
      "\n",
      "--- FREEDOM ---\n",
      "Shape: (1458, 123)\n",
      "Columns: ['year', 'iso_code', 'countries', 'region', 'pf_rol_procedural', 'pf_rol_civil', 'pf_rol_criminal', 'pf_rol', 'pf_ss_homicide', 'pf_ss_disappearances_disap', 'pf_ss_disappearances_violent', 'pf_ss_disappearances_organized', 'pf_ss_disappearances_fatalities', 'pf_ss_disappearances_injuries', 'pf_ss_disappearances', 'pf_ss_women_fgm', 'pf_ss_women_missing', 'pf_ss_women_inheritance_widows', 'pf_ss_women_inheritance_daughters', 'pf_ss_women_inheritance', 'pf_ss_women', 'pf_ss', 'pf_movement_domestic', 'pf_movement_foreign', 'pf_movement_women', 'pf_movement', 'pf_religion_estop_establish', 'pf_religion_estop_operate', 'pf_religion_estop', 'pf_religion_harassment', 'pf_religion_restrictions', 'pf_religion', 'pf_association_association', 'pf_association_assembly', 'pf_association_political_establish', 'pf_association_political_operate', 'pf_association_political', 'pf_association_prof_establish', 'pf_association_prof_operate', 'pf_association_prof', 'pf_association_sport_establish', 'pf_association_sport_operate', 'pf_association_sport', 'pf_association', 'pf_expression_killed', 'pf_expression_jailed', 'pf_expression_influence', 'pf_expression_control', 'pf_expression_cable', 'pf_expression_newspapers', 'pf_expression_internet', 'pf_expression', 'pf_identity_legal', 'pf_identity_parental_marriage', 'pf_identity_parental_divorce', 'pf_identity_parental', 'pf_identity_sex_male', 'pf_identity_sex_female', 'pf_identity_sex', 'pf_identity_divorce', 'pf_identity', 'pf_score', 'pf_rank', 'ef_government_consumption', 'ef_government_transfers', 'ef_government_enterprises', 'ef_government_tax_income', 'ef_government_tax_payroll', 'ef_government_tax', 'ef_government', 'ef_legal_judicial', 'ef_legal_courts', 'ef_legal_protection', 'ef_legal_military', 'ef_legal_integrity', 'ef_legal_enforcement', 'ef_legal_restrictions', 'ef_legal_police', 'ef_legal_crime', 'ef_legal_gender', 'ef_legal', 'ef_money_growth', 'ef_money_sd', 'ef_money_inflation', 'ef_money_currency', 'ef_money', 'ef_trade_tariffs_revenue', 'ef_trade_tariffs_mean', 'ef_trade_tariffs_sd', 'ef_trade_tariffs', 'ef_trade_regulatory_nontariff', 'ef_trade_regulatory_compliance', 'ef_trade_regulatory', 'ef_trade_black', 'ef_trade_movement_foreign', 'ef_trade_movement_capital', 'ef_trade_movement_visit', 'ef_trade_movement', 'ef_trade', 'ef_regulation_credit_ownership', 'ef_regulation_credit_private', 'ef_regulation_credit_interest', 'ef_regulation_credit', 'ef_regulation_labor_minwage', 'ef_regulation_labor_firing', 'ef_regulation_labor_bargain', 'ef_regulation_labor_hours', 'ef_regulation_labor_dismissal', 'ef_regulation_labor_conscription', 'ef_regulation_labor', 'ef_regulation_business_adm', 'ef_regulation_business_bureaucracy', 'ef_regulation_business_start', 'ef_regulation_business_bribes', 'ef_regulation_business_licensing', 'ef_regulation_business_compliance', 'ef_regulation_business', 'ef_regulation', 'ef_score', 'ef_rank', 'hf_score', 'hf_rank', 'hf_quartile']\n",
      "Missing values: 24688\n",
      "\n",
      "--- DANGER ---\n",
      "Shape: (176, 11)\n",
      "Columns: ['country', 'mostdangerouscountriesforwomen_womenpeaceandsecurityindex_score_2023', 'mostdangerouscountriesforwomen_womensdangerindexwdi_totalscore_2019', 'mostdangerouscountriesforwomen_wdistreetsafety_2019', 'mostdangerouscountriesforwomen_wdiintentionalhomicide_2019', 'mostdangerouscountriesforwomen_wdinonpartnerviolence_2019', 'mostdangerouscountriesforwomen_wdiintimatepartnerviolence_2019', 'mostdangerouscountriesforwomen_wdilegaldiscrimination_2019', 'mostdangerouscountriesforwomen_wdiglobalgendergap_2019', 'mostdangerouscountriesforwomen_wdigenderinequality_2019', 'mostdangerouscountriesforwomen_wdiattitudestowardviolence_2019']\n",
      "Missing values: 1134\n",
      "\n",
      "--- GDP ---\n",
      "Shape: (266, 64)\n",
      "Columns: ['country_name', 'code', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', 'unnamed_65']\n",
      "Missing values: 3652\n",
      "\n",
      "--- WAGE_GAP ---\n",
      "Shape: (1210, 1)\n",
      "Columns: ['locationindicatorsubjectmeasurefrequencytimevalue']\n",
      "Missing values: 0\n",
      "\n",
      "--- UNEMPLOYMENT ---\n",
      "Shape: (1134, 16)\n",
      "Columns: ['country_name', 'indicator_name', 'sex', 'age_group', 'age_categories', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']\n",
      "Missing values: 30\n",
      "\n",
      "--- EDUCATION ---\n",
      "Shape: (202, 29)\n",
      "Columns: ['countries_and_areas', 'latitude', 'longitude', 'oosr_pre0primary_age_male', 'oosr_pre0primary_age_female', 'oosr_primary_age_male', 'oosr_primary_age_female', 'oosr_lower_secondary_age_male', 'oosr_lower_secondary_age_female', 'oosr_upper_secondary_age_male', 'oosr_upper_secondary_age_female', 'completion_rate_primary_male', 'completion_rate_primary_female', 'completion_rate_lower_secondary_male', 'completion_rate_lower_secondary_female', 'completion_rate_upper_secondary_male', 'completion_rate_upper_secondary_female', 'grade_2_3_proficiency_reading', 'grade_2_3_proficiency_math', 'primary_end_proficiency_reading', 'primary_end_proficiency_math', 'lower_secondary_end_proficiency_reading', 'lower_secondary_end_proficiency_math', 'youth_15_24_literacy_rate_male', 'youth_15_24_literacy_rate_female', 'birth_rate', 'gross_primary_education_enrollment', 'gross_tertiary_education_enrollment', 'unemployment_rate']\n",
      "Missing values: 0\n",
      "\n",
      "--- GII ---\n",
      "Shape: (195, 11)\n",
      "Columns: ['country', 'human_development', 'gii', 'rank', 'maternal_mortality', 'adolescent_birth_rate', 'seats_parliament', 'f_secondary_educ', 'm_secondary_educ', 'f_labour_force', 'm_labour_force']\n",
      "Missing values: 133\n",
      "\n",
      "--- LEGAL ---\n",
      "Shape: (282, 4)\n",
      "Columns: ['country', 'year', '511___legal_frameworks', 'unnamed_3']\n",
      "Missing values: 0\n",
      "\n",
      "--- PARTNER_VIOLENCE ---\n",
      "Shape: (156, 34)\n",
      "Columns: ['IndicatorCode', 'Indicator', 'ValueType', 'ParentLocationCode', 'ParentLocation', 'Location type', 'SpatialDimValueCode', 'Location', 'Period type', 'Period', 'IsLatestYear', 'Dim1 type', 'Dim1', 'Dim1ValueCode', 'Dim2 type', 'Dim2', 'Dim2ValueCode', 'Dim3 type', 'Dim3', 'Dim3ValueCode', 'DataSourceDimValueCode', 'DataSource', 'FactValueNumericPrefix', 'FactValueNumeric', 'FactValueUoM', 'FactValueNumericLowPrefix', 'FactValueNumericLow', 'FactValueNumericHighPrefix', 'FactValueNumericHigh', 'Value', 'FactValueTranslationID', 'FactComments', 'Language', 'DateModified']\n",
      "Missing values: 2652\n",
      "\n",
      "--- EQ_LAWS ---\n",
      "Shape: (378, 8)\n",
      "Columns: ['entity', 'year', 'employment_discrimination_law', 'equal_remuneration_law', 'maternity_leave', 'domestic_violence_legislation', 'property_rights_equality', 'business_registration_equality']\n",
      "Missing values: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"domestic\": dv_df_clean,\n",
    "    \"vawg\": vawg_df_clean,\n",
    "    \"freedom\": hfi_df_clean,\n",
    "    \"danger\": mdc_df_clean,\n",
    "    \"gdp\": gdp_df_clean,\n",
    "    \"wage_gap\": gwg_df_clean,\n",
    "    \"unemployment\": gud_df_clean,\n",
    "    \"gii\": gii_df_clean,\n",
    "    \"legal\": lf_df_clean,\n",
    "    \"partner_violence\": aip_df_clean,\n",
    "    \"eq_laws\": gel_df_clean\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"--- {name.upper()} ---\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    print(\"Missing values:\", df.isna().sum().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4710a7f",
   "metadata": {},
   "source": [
    "## 3. Select Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65c4db",
   "metadata": {},
   "source": [
    "### 3.1 Domestic Violence\n",
    "\n",
    "- droping case number\n",
    "- no missing values\n",
    "- potential further processing:\n",
    "    income bucktes (no, low, middle, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "9e941028",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_df_pro = dv_df_clean.drop(columns=\"sl_no\")\n",
    "\n",
    "categorical_columns = ['education', 'employment', 'marital_status', 'violence']\n",
    "for col in categorical_columns:\n",
    "    dv_df_pro[col] = dv_df_pro[col].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffa7c0",
   "metadata": {},
   "source": [
    "### 3.2 Violence Against Women & Girls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "d8334476",
   "metadata": {},
   "outputs": [],
   "source": [
    "vawg_df_pro = vawg_df_clean.drop(columns=\"survey_year\")\n",
    "\n",
    "#create demographic group column (text normalized)\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = s.replace(\" \", \"_\")\n",
    "    s = s.replace(\"-\", \"_\")\n",
    "    s = s.replace(\",\", \"\")\n",
    "    return s\n",
    "\n",
    "vawg_df_pro[\"demographic_group\"] = (\n",
    "    vawg_df_pro[\"demographics_question\"].apply(normalize_text)\n",
    "    + \"_\" +\n",
    "    vawg_df_pro[\"demographics_response\"].apply(normalize_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "3f3f9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table\n",
    "def pivot_vawg(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=[\"country\", \"question\"],\n",
    "        columns=\"demographic_group\",\n",
    "        values=\"value\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "\n",
    "    pivot_df = pivot_df.reset_index()\n",
    "\n",
    "    # Fix column names: remove pivot table formatting\n",
    "    pivot_df.columns = [str(col) for col in pivot_df.columns]\n",
    "\n",
    "    return pivot_df\n",
    "\n",
    "\n",
    "vawg_df_pro = pivot_vawg(vawg_df_pro)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "6279a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['country', 'question']\n",
    "for col in categorical_columns:\n",
    "    vawg_df_pro[col] = vawg_df_pro[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "40d5ec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 sparse columns: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\3198293871.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>question</th>\n",
       "      <th>age_15_24</th>\n",
       "      <th>age_25_34</th>\n",
       "      <th>age_35_49</th>\n",
       "      <th>education_higher</th>\n",
       "      <th>education_no_education</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>employment_employed_for_cash</th>\n",
       "      <th>employment_employed_for_kind</th>\n",
       "      <th>employment_unemployed</th>\n",
       "      <th>marital_status_married_or_living_together</th>\n",
       "      <th>marital_status_never_married</th>\n",
       "      <th>marital_status_widowed_divorced_separated</th>\n",
       "      <th>residence_rural</th>\n",
       "      <th>residence_urban</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>for at least one specific reason</td>\n",
       "      <td>77.10</td>\n",
       "      <td>76.00</td>\n",
       "      <td>76.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>79.20</td>\n",
       "      <td>73.95</td>\n",
       "      <td>72.80</td>\n",
       "      <td>76.40</td>\n",
       "      <td>80.20</td>\n",
       "      <td>73.75</td>\n",
       "      <td>76.60</td>\n",
       "      <td>15.1</td>\n",
       "      <td>58.20</td>\n",
       "      <td>79.10</td>\n",
       "      <td>66.95</td>\n",
       "      <td>Afghanistan | for at least one specific reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>if she argues with him</td>\n",
       "      <td>50.95</td>\n",
       "      <td>52.30</td>\n",
       "      <td>53.20</td>\n",
       "      <td>34.55</td>\n",
       "      <td>55.20</td>\n",
       "      <td>48.95</td>\n",
       "      <td>49.10</td>\n",
       "      <td>51.65</td>\n",
       "      <td>50.65</td>\n",
       "      <td>50.45</td>\n",
       "      <td>52.50</td>\n",
       "      <td>15.1</td>\n",
       "      <td>43.30</td>\n",
       "      <td>53.80</td>\n",
       "      <td>47.55</td>\n",
       "      <td>Afghanistan | if she argues with him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>if she burns the food</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.20</td>\n",
       "      <td>13.70</td>\n",
       "      <td>7.30</td>\n",
       "      <td>14.85</td>\n",
       "      <td>10.05</td>\n",
       "      <td>10.40</td>\n",
       "      <td>14.60</td>\n",
       "      <td>13.85</td>\n",
       "      <td>11.60</td>\n",
       "      <td>13.40</td>\n",
       "      <td>15.1</td>\n",
       "      <td>10.05</td>\n",
       "      <td>13.90</td>\n",
       "      <td>11.45</td>\n",
       "      <td>Afghanistan | if she burns the food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>if she goes out without informing him</td>\n",
       "      <td>65.50</td>\n",
       "      <td>64.45</td>\n",
       "      <td>62.85</td>\n",
       "      <td>42.35</td>\n",
       "      <td>67.20</td>\n",
       "      <td>60.00</td>\n",
       "      <td>58.85</td>\n",
       "      <td>63.80</td>\n",
       "      <td>66.85</td>\n",
       "      <td>60.90</td>\n",
       "      <td>64.20</td>\n",
       "      <td>15.1</td>\n",
       "      <td>47.50</td>\n",
       "      <td>67.45</td>\n",
       "      <td>52.45</td>\n",
       "      <td>Afghanistan | if she goes out without informin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>if she neglects the children</td>\n",
       "      <td>35.65</td>\n",
       "      <td>38.60</td>\n",
       "      <td>36.90</td>\n",
       "      <td>27.15</td>\n",
       "      <td>39.30</td>\n",
       "      <td>36.45</td>\n",
       "      <td>33.70</td>\n",
       "      <td>36.85</td>\n",
       "      <td>39.95</td>\n",
       "      <td>40.20</td>\n",
       "      <td>37.35</td>\n",
       "      <td>15.1</td>\n",
       "      <td>36.20</td>\n",
       "      <td>38.50</td>\n",
       "      <td>33.15</td>\n",
       "      <td>Afghanistan | if she neglects the children</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country                               question  age_15_24  age_25_34  \\\n",
       "0  Afghanistan       for at least one specific reason      77.10      76.00   \n",
       "1  Afghanistan                 if she argues with him      50.95      52.30   \n",
       "2  Afghanistan                  if she burns the food      13.35      13.20   \n",
       "3  Afghanistan  if she goes out without informing him      65.50      64.45   \n",
       "4  Afghanistan           if she neglects the children      35.65      38.60   \n",
       "\n",
       "   age_35_49  education_higher  education_no_education  education_primary  \\\n",
       "0      76.30             58.30                   79.20              73.95   \n",
       "1      53.20             34.55                   55.20              48.95   \n",
       "2      13.70              7.30                   14.85              10.05   \n",
       "3      62.85             42.35                   67.20              60.00   \n",
       "4      36.90             27.15                   39.30              36.45   \n",
       "\n",
       "   education_secondary  employment_employed_for_cash  \\\n",
       "0                72.80                         76.40   \n",
       "1                49.10                         51.65   \n",
       "2                10.40                         14.60   \n",
       "3                58.85                         63.80   \n",
       "4                33.70                         36.85   \n",
       "\n",
       "   employment_employed_for_kind  employment_unemployed  \\\n",
       "0                         80.20                  73.75   \n",
       "1                         50.65                  50.45   \n",
       "2                         13.85                  11.60   \n",
       "3                         66.85                  60.90   \n",
       "4                         39.95                  40.20   \n",
       "\n",
       "   marital_status_married_or_living_together  marital_status_never_married  \\\n",
       "0                                      76.60                          15.1   \n",
       "1                                      52.50                          15.1   \n",
       "2                                      13.40                          15.1   \n",
       "3                                      64.20                          15.1   \n",
       "4                                      37.35                          15.1   \n",
       "\n",
       "   marital_status_widowed_divorced_separated  residence_rural  \\\n",
       "0                                      58.20            79.10   \n",
       "1                                      43.30            53.80   \n",
       "2                                      10.05            13.90   \n",
       "3                                      47.50            67.45   \n",
       "4                                      36.20            38.50   \n",
       "\n",
       "   residence_urban                                                key  \n",
       "0            66.95     Afghanistan | for at least one specific reason  \n",
       "1            47.55               Afghanistan | if she argues with him  \n",
       "2            11.45                Afghanistan | if she burns the food  \n",
       "3            52.45  Afghanistan | if she goes out without informin...  \n",
       "4            33.15         Afghanistan | if she neglects the children  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values\n",
    "\n",
    "def impute_vawg(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Impute missing values in VAWG demographic % data.\n",
    "    Strategy:\n",
    "        1) If missing → country median for that question\n",
    "        2) If still missing → global median for that demographic column\n",
    "    \"\"\"\n",
    "    id_cols = [\"country\", \"question\"]\n",
    "    feature_cols = [c for c in df.columns if c not in id_cols]\n",
    "\n",
    "    for feature in feature_cols:\n",
    "        df[feature] = df.groupby([\"country\", \"question\"])[feature].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "\n",
    "    for feature in feature_cols:\n",
    "        if df[feature].isna().sum() > 0:\n",
    "            df[feature] = df[feature].fillna(df[feature].median())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean Question\n",
    "\n",
    "def clean_question_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize violence-related question text to ensure consistent keys.\n",
    "    \"\"\"\n",
    "    df[\"question\"] = df[\"question\"].str.replace(r\"^\\.\\.\\.\\s*\", \"\", regex=True)\n",
    "\n",
    "    # Text normalization: lowercase, strip, unify spaces\n",
    "    df[\"question\"] = (\n",
    "        df[\"question\"]\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    )\n",
    "\n",
    "    # Unify similar question labels\n",
    "    replacements = {\n",
    "        \"if she burns food\": \"if she burns the food\",\n",
    "        \"if she burns the food?\": \"if she burns the food\",\n",
    "        \"if she goes out without telling him\": \"if she goes out without informing him\",\n",
    "    }\n",
    "\n",
    "    df[\"question\"] = df[\"question\"].replace(replacements)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# romve columns with high missing values\n",
    "\n",
    "def drop_sparse_columns(df: pd.DataFrame, threshold: float = 0.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drops columns with more than threshold % missing values.\n",
    "    threshold=0.5 -> drop columns with >50% missing.\n",
    "    \"\"\"\n",
    "\n",
    "    id_cols = [\"country\", \"question\"]\n",
    "    feature_cols = [c for c in df.columns if c not in id_cols]\n",
    "\n",
    "    missing_ratio = df[feature_cols].isna().mean()\n",
    "    drop_cols = missing_ratio[missing_ratio > threshold].index.tolist()\n",
    "\n",
    "    print(f\"Dropping {len(drop_cols)} sparse columns: {drop_cols}\")\n",
    "\n",
    "    df = df.drop(columns=drop_cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# unique key (country + question)\n",
    "\n",
    "def create_unique_key(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    for later modeling\n",
    "    \"\"\"\n",
    "    df[\"key\"] = df[\"country\"].astype(str) + \" | \" + df[\"question\"].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "# pipeline\n",
    "\n",
    "def clean_vawg_full(vawg_df_pro: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = vawg_df_pro.copy()\n",
    "    df = clean_question_text(df)\n",
    "    df = impute_vawg(df)\n",
    "    df = drop_sparse_columns(df, threshold=0.5)\n",
    "    df = create_unique_key(df)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# apply\n",
    "\n",
    "vawg_df_pro = clean_vawg_full(vawg_df_pro)\n",
    "vawg_df_pro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028d017",
   "metadata": {},
   "source": [
    "### 3.3 Violence/Sexual Abuse Current or former partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "af3bdef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\1145058609.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aip_df_pro['value'] = aip_df_pro['value'].str.replace(r'\\s*\\[.*?\\]', '', regex=True)\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_31060\\1145058609.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aip_df_pro['value'] = aip_df_pro['value'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "# only select needed values\n",
    "aip_df_pro = aip_df_clean[[\"location\", \"value\"]]\n",
    "\n",
    "# remove everything in square brackets including the brackets\n",
    "aip_df_pro['value'] = aip_df_pro['value'].str.replace(r'\\s*\\[.*?\\]', '', regex=True)\n",
    "\n",
    "# trip any whitespace\n",
    "aip_df_pro['value'] = aip_df_pro['value'].str.strip()\n",
    "\n",
    "# rename column\n",
    "aip_df_pro = aip_df_pro.rename(columns={\"location\" :  \"country\"})\n",
    "\n",
    "# change value type\n",
    "cat_col_vawg= ['country']\n",
    "for col in cat_col_vawg:\n",
    "    aip_df_pro[col] = aip_df_pro[col].astype('category')\n",
    "\n",
    "\n",
    "num_col_vawg= ['value']\n",
    "for col in num_col_vawg:\n",
    "    aip_df_pro[col] = aip_df_pro[col].astype('int')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851ea34",
   "metadata": {},
   "source": [
    "### 3.4 Human Freedom Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "4071286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfi_df_clean = pd.read_csv(r\"data\\clean\\gsutters_the-human-freedom-index\\hfi_cc_2022.csv\")\n",
    "hfi_df_clean.columns.tolist()\n",
    "\n",
    "# choose only needed data \n",
    "hfi_df_pro = hfi_df_clean[[\"year\", \"countries\", \"region\", \"hf_score\", 'pf_score', 'ef_score']]\n",
    "\n",
    "# only use latest data (2020) -> all available, better as mean from all years due to NaNs\n",
    "hfi_df_pro  = hfi_df_pro[hfi_df_pro[\"year\"] == 2020]\n",
    "\n",
    "# drop year column \n",
    "hfi_df_pro = hfi_df_pro.drop(columns=[\"year\"])\n",
    "\n",
    "# rename columns\n",
    "hfi_df_pro = hfi_df_pro.rename(columns={\"countries\" : \"country\"})\n",
    "\n",
    "# change value type\n",
    "cat_col_hfi = ['country', 'region']\n",
    "for col in cat_col_hfi:\n",
    "    hfi_df_pro[col] = hfi_df_pro[col].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f7216",
   "metadata": {},
   "source": [
    "### 3.5 Most Dangerous Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "6cfecd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdc_df_clean.head()\n",
    "\n",
    "# rename columns\n",
    "mdc_df_pro = mdc_df_clean.rename(columns={\n",
    "    \"mostdangerouscountriesforwomen_womenpeaceandsecurityindex_score_2023\" : \"wpsi\",\n",
    "    \"mostdangerouscountriesforwomen_womensdangerindexwdi_totalscore_2019\" : \"wdi\",\n",
    "    \"mostdangerouscountriesforwomen_wdistreetsafety_2019\" : \"wss\",\n",
    "    \"mostdangerouscountriesforwomen_wdiintentionalhomicide_2019\" : \"ih\",\n",
    "    \"mostdangerouscountriesforwomen_wdinonpartnerviolence_2019\" : \"npv\",\n",
    "    \"mostdangerouscountriesforwomen_wdiintimatepartnerviolence_2019\" : \"ipv\",\n",
    "    \"mostdangerouscountriesforwomen_wdilegaldiscrimination_2019\" : \"ld\",\n",
    "    \"mostdangerouscountriesforwomen_wdiglobalgendergap_2019\" : \"ggg\",\n",
    "    \"mostdangerouscountriesforwomen_wdigenderinequality_2019\" : \"gi\",\n",
    "    \"mostdangerouscountriesforwomen_wdiattitudestowardviolence_2019\" : \"atv\"\n",
    "    })\n",
    "\n",
    "\n",
    "# split into two data sets due to missing values\n",
    "# 1. Women Peace and Security Index 2023 (all countries): WPSI\n",
    "wpsi_df_pro = mdc_df_pro[[\"country\", \"wpsi\"]]\n",
    "\n",
    "# 2. Women Danger index + respective parameters; remove ggg & gi as given in other data\n",
    "mdc_df_pro = mdc_df_pro.drop(columns=[\"wpsi\", \"ggg\", \"gi\"])\n",
    "\n",
    "# drop missing values\n",
    "mdc_df_pro = mdc_df_pro.dropna()\n",
    "\n",
    "# reset index\n",
    "mdc_df_pro = mdc_df_pro.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a6daa",
   "metadata": {},
   "source": [
    "### 3.6 GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "0afda95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping relevant columns\n",
    "gdp_df_pro = gdp_df_clean[['country_name', 'code', '2020']]\n",
    "\n",
    "# rename columns\n",
    "gdp_df_pro = gdp_df_pro.rename(columns={'country_name' : \"country\", 'code' : \"iso\", '2020' : \"gdp\"})\n",
    "\n",
    "# manual fill-in NaN\n",
    "gdp_df_pro[gdp_df_pro.isna().any(axis=1)]\n",
    "\n",
    "gdp_df_pro.iloc[0, 2] = 2.482e+9\n",
    "gdp_df_pro.iloc[6, 2] = 2.891e+9\n",
    "gdp_df_pro.iloc[38, 2] = 9.44e+9\n",
    "gdp_df_pro.iloc[69, 2] = 2.084e+9\n",
    "gdp_df_pro.iloc[78, 2] = 3.272e+9\n",
    "gdp_df_pro.iloc[84, 2] = 3e+9\n",
    "gdp_df_pro.iloc[91, 2] = 3.08e+9\n",
    "gdp_df_pro.iloc[108, 2] = 6.68e+9\n",
    "gdp_df_pro.iloc[137, 2] = 2.2e+9\n",
    "gdp_df_pro.iloc[172, 2] = 9.45e+9\n",
    "gdp_df_pro.iloc[193, 2] = 1.5847e+10\n",
    "gdp_df_pro.iloc[199, 2] = 5.79e+9\n",
    "gdp_df_pro.iloc[216, 2] = 5.4e+9\n",
    "gdp_df_pro.iloc[227, 2] = 1.205e+10\n",
    "gdp_df_pro.iloc[235, 2] = 4.582e+10\n",
    "gdp_df_pro.iloc[254, 2] = 8.277e+10\n",
    "gdp_df_pro.iloc[235, 2] = 4.582e+10\n",
    "gdp_df_pro.iloc[262, 2] = 2.02e+10\n",
    "\n",
    "# delete unsignificant rows\n",
    "gdp_df_pro = gdp_df_pro.drop([110, 147, 164, 212, 225, 255, 256])\n",
    "\n",
    "# log GDP to reduce skeweness\n",
    "gdp_df_pro[\"log_GDP\"] = np.log10(gdp_df_pro[\"gdp\"])\n",
    "\n",
    "# drop non-log GDP\n",
    "gdp_df_pro = gdp_df_pro.drop(columns=[\"gdp\"])\n",
    "\n",
    "# change value type\n",
    "cat_col_gdp= ['country', \"iso\"]\n",
    "for col in cat_col_gdp:\n",
    "    gdp_df_pro[col] = gdp_df_pro[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591f476",
   "metadata": {},
   "source": [
    "### 3.7 Gender Wage Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789603b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CategoricalDtype(categories=['AUS', 'AUT', 'BEL', 'BGR', 'CAN', 'CHE', 'COL', 'CRI',\n",
       "                   'CYP', 'CZE', 'DEU', 'DNK', 'ESP', 'EST', 'EU27', 'FIN',\n",
       "                   'FRA', 'GBR', 'GRC', 'HRV', 'HUN', 'IRL', 'ISL', 'ISR',\n",
       "                   'ITA', 'JPN', 'KOR', 'LTU', 'LVA', 'MEX', 'MLT', 'NLD',\n",
       "                   'NOR', 'NZL', 'OECD', 'POL', 'PRT', 'ROU', 'SVK', 'SVN',\n",
       "                   'SWE', 'TUR', 'USA'],\n",
       " , ordered=False, categories_dtype=object),\n",
       " dtype('float64')]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data into right format\n",
    "column_names = ['iso', 'indicator', 'subject', 'measure', 'frequency', 'time', 'gwg_%']\n",
    "\n",
    "gwg_df_pro = gwg_df_clean['locationindicatorsubjectmeasurefrequencytimevalue'].str.split(';', expand=True)\n",
    "\n",
    "gwg_df_pro.columns = column_names\n",
    "\n",
    "# only select useful data\n",
    "gwg_df_pro = gwg_df_pro[gwg_df_pro[\"time\"] == \"2018\"]  \n",
    "\n",
    "gwg_df_pro = gwg_df_pro[gwg_df_pro[\"subject\"] != \"SELFEMPLOYED\"]\n",
    "\n",
    "gwg_df_pro = gwg_df_pro[[\"iso\", \"gwg_%\"]]\n",
    "\n",
    "# change gwg_% format \n",
    "gwg_df_pro[\"gwg_%\"] = gwg_df_pro[\"gwg_%\"].astype(str).str.split(\".\").str[:2].str.join(\".\").astype(float)\n",
    "\n",
    "# reset index\n",
    "gwg_df_pro = gwg_df_pro.reset_index(drop=True)\n",
    "\n",
    "# change value type\n",
    "cat_col_gwg= [\"iso\"]\n",
    "for col in cat_col_gwg:\n",
    "    gwg_df_pro[col] = gwg_df_pro[col].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66171def",
   "metadata": {},
   "source": [
    "### 3.8 Global Unemployment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "fde05255",
   "metadata": {},
   "outputs": [],
   "source": [
    "gud_df_clean.head()\n",
    "\n",
    "# select relevant columns\n",
    "gud_df_pro = gud_df_clean[[\"country_name\", \"sex\", \"age_group\", \"2024\"]]\n",
    "\n",
    "# rename columnc \n",
    "gud_df_pro = gud_df_pro.rename(columns={\"country_name\" : \"country\", \"age_group\" : \"age\", \"2024\" : \"percentage_unemployement\"})\n",
    "\n",
    "# handle missing values\n",
    "gud_df_pro[gud_df_pro.isna().any(axis=1)]\n",
    "\n",
    "# fill Palestinian Territories with data from 2022\n",
    "gud_df_pro.iloc[756, 3] = 56.709\n",
    "gud_df_pro.iloc[757, 3] = 36.385\n",
    "gud_df_pro.iloc[758, 3] = 40.045\n",
    "gud_df_pro.iloc[759, 3] = 31.563\n",
    "gud_df_pro.iloc[760, 3] = 16.772\n",
    "gud_df_pro.iloc[761, 3] = 20.186\n",
    "\n",
    "# fill Ukraine with data from 2021\n",
    "gud_df_pro.iloc[1056, 3] = 20.412\n",
    "gud_df_pro.iloc[1057, 3] = 9.519\n",
    "gud_df_pro.iloc[1058, 3] = 10.143\n",
    "gud_df_pro.iloc[1059, 3] = 18.085\n",
    "gud_df_pro.iloc[1060, 3] = 8.933\n",
    "gud_df_pro.iloc[1061, 3] = 9.543\n",
    "\n",
    "# change value type\n",
    "cat_col_gud= [\"country\", \"sex\", \"age\"]\n",
    "for col in cat_col_gud:\n",
    "    gud_df_pro[col] = gud_df_pro[col].astype('category')\n",
    "\n",
    "# reset index\n",
    "gud_df_pro  = gud_df_pro.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49897c65",
   "metadata": {},
   "source": [
    "### 3.9 Global Ineguality Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "e05fc95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>human_development</th>\n",
       "      <th>gii</th>\n",
       "      <th>rank</th>\n",
       "      <th>maternal_mortality</th>\n",
       "      <th>adolescent_birth_rate</th>\n",
       "      <th>seats_parliament</th>\n",
       "      <th>f_secondary_educ</th>\n",
       "      <th>m_secondary_educ</th>\n",
       "      <th>f_labour_force</th>\n",
       "      <th>m_labour_force</th>\n",
       "      <th>iso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Very high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.1</td>\n",
       "      <td>83.4</td>\n",
       "      <td>53.5</td>\n",
       "      <td>65.8</td>\n",
       "      <td>HKG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Liechtenstein</td>\n",
       "      <td>Very high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Very high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "      <td>46.4</td>\n",
       "      <td>70.7</td>\n",
       "      <td>72.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>Very high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>33.3</td>\n",
       "      <td>81.8</td>\n",
       "      <td>84.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Grenada</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>32.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Seychelles</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Saint Kitts and Nevis</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Palau</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>97.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PLW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Dominica</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Palestine</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.9</td>\n",
       "      <td>67.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>66.3</td>\n",
       "      <td>PSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TUV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>91.6</td>\n",
       "      <td>92.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MHL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Micronesia</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Kiribati</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.7</td>\n",
       "      <td>78.0</td>\n",
       "      <td>VUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Equatorial Guinea</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.0</td>\n",
       "      <td>139.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.9</td>\n",
       "      <td>58.5</td>\n",
       "      <td>GNQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>60.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.1</td>\n",
       "      <td>87.4</td>\n",
       "      <td>SLB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Comoros</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.0</td>\n",
       "      <td>58.2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Djibouti</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>26.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>44.1</td>\n",
       "      <td>DJI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Eritrea</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.0</td>\n",
       "      <td>64.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.2</td>\n",
       "      <td>83.6</td>\n",
       "      <td>ERI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>North Korea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.2</td>\n",
       "      <td>86.1</td>\n",
       "      <td>PRK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>33.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Somalia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>829.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.9</td>\n",
       "      <td>47.0</td>\n",
       "      <td>SOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country human_development  gii  rank  maternal_mortality  \\\n",
       "3                Hong Kong         Very high  NaN   NaN                 NaN   \n",
       "15           Liechtenstein         Very high  NaN   NaN                 NaN   \n",
       "39                 Andorra         Very high  NaN   NaN                 NaN   \n",
       "43              San Marino         Very high  NaN   NaN                 NaN   \n",
       "68                 Grenada              High  NaN   NaN                25.0   \n",
       "70     Antigua and Barbuda              High  NaN   NaN                42.0   \n",
       "71              Seychelles              High  NaN   NaN                53.0   \n",
       "74   Saint Kitts and Nevis              High  NaN   NaN                 NaN   \n",
       "81                   Palau              High  NaN   NaN                 NaN   \n",
       "101               Dominica              High  NaN   NaN                 NaN   \n",
       "105              Palestine              High  NaN   NaN                27.0   \n",
       "129                 Tuvalu            Medium  NaN   NaN                 NaN   \n",
       "130       Marshall Islands            Medium  NaN   NaN                 NaN   \n",
       "133             Micronesia            Medium  NaN   NaN                88.0   \n",
       "135               Kiribati            Medium  NaN   NaN                92.0   \n",
       "141                Vanuatu            Medium  NaN   NaN                72.0   \n",
       "144      Equatorial Guinea            Medium  NaN   NaN               301.0   \n",
       "154        Solomon Islands            Medium  NaN   NaN               104.0   \n",
       "155                Comoros            Medium  NaN   NaN               273.0   \n",
       "170               Djibouti               Low  NaN   NaN               248.0   \n",
       "175                Eritrea               Low  NaN   NaN               480.0   \n",
       "191            North Korea               NaN  NaN   NaN                89.0   \n",
       "192                 Monaco               NaN  NaN   NaN                 NaN   \n",
       "193                  Nauru               NaN  NaN   NaN                 NaN   \n",
       "194                Somalia               NaN  NaN   NaN               829.0   \n",
       "\n",
       "     adolescent_birth_rate  seats_parliament  f_secondary_educ  \\\n",
       "3                      1.6               NaN              77.1   \n",
       "15                     3.0              28.0               NaN   \n",
       "39                     5.9              46.4              70.7   \n",
       "43                     3.8              33.3              81.8   \n",
       "68                    32.7              32.1               NaN   \n",
       "70                    33.1              31.4               NaN   \n",
       "71                    53.4              22.9               NaN   \n",
       "74                    38.2              25.0               NaN   \n",
       "81                    42.5               6.9              96.9   \n",
       "101                   38.5              34.4               NaN   \n",
       "105                   43.5               NaN              67.9   \n",
       "129                   33.1               6.3              60.0   \n",
       "130                   58.0               6.1              91.6   \n",
       "133                   35.8               7.1               NaN   \n",
       "135                   40.5               6.7               NaN   \n",
       "141                   64.1               0.0               NaN   \n",
       "144                  139.7              20.3               NaN   \n",
       "154                   60.3               8.0               NaN   \n",
       "155                   58.2              16.7               NaN   \n",
       "170                   22.7              26.2               NaN   \n",
       "175                   64.4              22.0               NaN   \n",
       "191                    2.3              17.6               NaN   \n",
       "192                    7.2              33.3               NaN   \n",
       "193                   72.5              10.5               NaN   \n",
       "194                  118.0              24.6               NaN   \n",
       "\n",
       "     m_secondary_educ  f_labour_force  m_labour_force  iso  \n",
       "3                83.4            53.5            65.8  HKG  \n",
       "15                NaN             NaN             NaN  LIE  \n",
       "39               72.4             NaN             NaN  AND  \n",
       "43               84.3             NaN             NaN  SMR  \n",
       "68                NaN             NaN             NaN  GRD  \n",
       "70                NaN             NaN             NaN  ATG  \n",
       "71                NaN             NaN             NaN  SYC  \n",
       "74                NaN             NaN             NaN  KNA  \n",
       "81               97.3             NaN             NaN  PLW  \n",
       "101               NaN             NaN             NaN  DMA  \n",
       "105              67.6            16.7            66.3  PSE  \n",
       "129              60.7             NaN             NaN  TUV  \n",
       "130              92.5             NaN             NaN  MHL  \n",
       "133               NaN             NaN             NaN  FSM  \n",
       "135               NaN             NaN             NaN  KIR  \n",
       "141               NaN            59.7            78.0  VUT  \n",
       "144               NaN            49.9            58.5  GNQ  \n",
       "154               NaN            83.1            87.4  SLB  \n",
       "155               NaN            32.1            54.5  COM  \n",
       "170               NaN            17.2            44.1  DJI  \n",
       "175               NaN            70.2            83.6  ERI  \n",
       "191               NaN            77.2            86.1  PRK  \n",
       "192               NaN             NaN             NaN  MCO  \n",
       "193               NaN             NaN             NaN  NRU  \n",
       "194               NaN            20.9            47.0  SOM  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gii_df_clean[gii_df_clean.isna().any(axis=1)]\n",
    "\n",
    "# missing values handling open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac02fd8",
   "metadata": {},
   "source": [
    "### 3.10 Legal Frameworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "342fc5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legal frameworks that promote, enforce and monitor gender equality (percentage of achievement, 0 - 100)\n",
    "\n",
    "lf_df_pro = lf_df_clean.drop(columns = \"unnamed_3\")\n",
    "lf_df_pro = lf_df_pro.rename(columns = {\"511___legal_frameworks\" : \"percent_leg_equ_achiev_marriage\"})\n",
    "lf_df_pro = lf_df_pro[lf_df_pro[\"year\"] == 2022]\n",
    "lf_df_pro = lf_df_pro.drop(columns=\"year\")\n",
    "\n",
    "cat_col_lf= [\"country\"]\n",
    "for col in cat_col_lf:\n",
    "    lf_df_pro[col] = lf_df_pro[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5474837",
   "metadata": {},
   "source": [
    "### 3.11 Equality Laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "e843c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select latest data\n",
    "gel_df_pro = gel_df_clean[gel_df_clean[\"year\"] == 2023]\n",
    "\n",
    "# rename columns\n",
    "gel_df_pro = gel_df_pro.rename(columns={\"entity\" : \"continent\"})\n",
    "\n",
    "# drop unnessecary columns\n",
    "gel_df_pro = gel_df_pro.drop(columns=[\"year\"])\n",
    "\n",
    "# reset index\n",
    "gel_df_pro = gel_df_pro.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b155d1",
   "metadata": {},
   "source": [
    "## 4. ISO Country Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2242c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: DOMESTIC\n",
      "============================================================\n",
      "Skipping (no country column or already has ISO)\n",
      "\n",
      "============================================================\n",
      "Processing: VAWG\n",
      "============================================================\n",
      "All countries successfully matched!\n",
      "\n",
      "Matching Summary:\n",
      "   Total rows: 415\n",
      "   Matched: 415 (100.0%)\n",
      "   Unmatched: 0 (0.0%)\n",
      "\n",
      "============================================================\n",
      "Processing: FREEDOM\n",
      "============================================================\n",
      "All countries successfully matched!\n",
      "\n",
      "Matching Summary:\n",
      "   Total rows: 165\n",
      "   Matched: 165 (100.0%)\n",
      "   Unmatched: 0 (0.0%)\n",
      "\n",
      "============================================================\n",
      "Processing: DANGER\n",
      "============================================================\n",
      "All countries successfully matched!\n",
      "\n",
      "Matching Summary:\n",
      "   Total rows: 50\n",
      "   Matched: 50 (100.0%)\n",
      "   Unmatched: 0 (0.0%)\n",
      "\n",
      "============================================================\n",
      "Processing: GDP\n",
      "============================================================\n",
      "Already has 'iso' column\n",
      "\n",
      "============================================================\n",
      "Processing: WAGE_GAP\n",
      "============================================================\n",
      "Skipping (no country column or already has ISO)\n",
      "\n",
      "============================================================\n",
      "Processing: UNEMPLOYMENT\n",
      "============================================================\n",
      "All countries successfully matched!\n",
      "\n",
      "Matching Summary:\n",
      "   Total rows: 1134\n",
      "   Matched: 1134 (100.0%)\n",
      "   Unmatched: 0 (0.0%)\n",
      "\n",
      "============================================================\n",
      "Processing: GII\n",
      "============================================================\n",
      "Already has 'iso' column\n",
      "\n",
      "============================================================\n",
      "Processing: LEGAL\n",
      "============================================================\n",
      "\n",
      "Warning: 8 countries could not be matched:\n",
      "  - Central and Southern Asia (UN)\n",
      "  - Eastern and South-Eastern Asia (UN)\n",
      "  - Europe and Northern America (UN)\n",
      "  - Latin America and the Caribbean (UN)\n",
      "  - Least Developed Countries (LDCs)\n",
      "  - Small Island Developing States (SIDS)\n",
      "  - Sub-Saharan Africa (UN)\n",
      "  - World\n",
      "\n",
      "Consider adding these to the manual mapping.\n",
      "\n",
      "Matching Summary:\n",
      "   Total rows: 127\n",
      "   Matched: 119 (93.7%)\n",
      "   Unmatched: 8 (6.3%)\n",
      "\n",
      "============================================================\n",
      "Processing: PARTNER_VIOLENCE\n",
      "============================================================\n",
      "All countries successfully matched!\n",
      "\n",
      "Matching Summary:\n",
      "   Total rows: 151\n",
      "   Matched: 151 (100.0%)\n",
      "   Unmatched: 0 (0.0%)\n",
      "\n",
      "============================================================\n",
      "Processing: EQ_LAWS\n",
      "============================================================\n",
      "\n",
      "Warning: 6 countries could not be matched:\n",
      "  - Africa\n",
      "  - Asia\n",
      "  - Europe\n",
      "  - North America\n",
      "  - Oceania\n",
      "  - World\n",
      "\n",
      "Consider adding these to the manual mapping.\n",
      "\n",
      "Matching Summary:\n",
      "   Total rows: 7\n",
      "   Matched: 1 (14.3%)\n",
      "   Unmatched: 6 (85.7%)\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "Datasets with unmatched countries:\n",
      "\n",
      "  LEGAL: 8 unmatched\n",
      "    - Central and Southern Asia (UN)\n",
      "    - Eastern and South-Eastern Asia (UN)\n",
      "    - Europe and Northern America (UN)\n",
      "    - Latin America and the Caribbean (UN)\n",
      "    - Least Developed Countries (LDCs)\n",
      "    - Small Island Developing States (SIDS)\n",
      "    - Sub-Saharan Africa (UN)\n",
      "    - World\n",
      "\n",
      "  EQ_LAWS: 6 unmatched\n",
      "    - Africa\n",
      "    - Asia\n",
      "    - Europe\n",
      "    - North America\n",
      "    - Oceania\n",
      "    - World\n"
     ]
    }
   ],
   "source": [
    "# datasets dictionary\n",
    "datasets = {\n",
    "    \"domestic\": dv_df_pro,\n",
    "    \"vawg\": vawg_df_pro,\n",
    "    \"freedom\": hfi_df_pro,\n",
    "    \"danger\": mdc_df_pro,\n",
    "    \"gdp\": gdp_df_pro,\n",
    "    \"wage_gap\": gwg_df_pro,\n",
    "    \"unemployment\": gud_df_pro,\n",
    "    \"gii\": gii_df_clean,\n",
    "    \"legal\": lf_df_pro,\n",
    "    \"partner_violence\": aip_df_pro,\n",
    "    \"eq_laws\": gel_df_pro\n",
    "}\n",
    "    \n",
    "# apply standardization\n",
    "updated_datasets, unmatched = standardize_all_countries(datasets)\n",
    "    \n",
    "# unpack updated datasets back to individual variables\n",
    "dv_df_pro = updated_datasets['domestic']\n",
    "vawg_df_pro = updated_datasets['vawg']\n",
    "hfi_df_pro = updated_datasets['freedom']\n",
    "mdc_df_pro = updated_datasets['danger']\n",
    "gdp_df_pro = updated_datasets['gdp']\n",
    "gwg_df_pro = updated_datasets['wage_gap']\n",
    "gud_df_pro = updated_datasets['unemployment']\n",
    "gii_df_clean = updated_datasets['gii']\n",
    "lf_df_pro = updated_datasets['legal']\n",
    "aip_df_pro = updated_datasets['partner_violence']\n",
    "gel_df_pro = updated_datasets['eq_laws']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07928e67",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "bf1d40dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DOMESTIC ---\n",
      "Shape: (347, 6)\n",
      "Columns: ['age', 'education', 'employment', 'income', 'marital_status', 'violence']\n",
      "Data types: [dtype('int64'), CategoricalDtype(categories=['none', 'primary', 'secondary', 'tertiary'], ordered=False, categories_dtype=object), CategoricalDtype(categories=['employed', 'semi employed', 'unemployed'], ordered=False, categories_dtype=object), dtype('int64'), CategoricalDtype(categories=['married', 'unmarred'], ordered=False, categories_dtype=object), CategoricalDtype(categories=['no', 'yes'], ordered=False, categories_dtype=object)]\n",
      "Missing values: 0\n",
      "\n",
      "--- VAWG ---\n",
      "Shape: (415, 19)\n",
      "Columns: ['country', 'question', 'age_15_24', 'age_25_34', 'age_35_49', 'education_higher', 'education_no_education', 'education_primary', 'education_secondary', 'employment_employed_for_cash', 'employment_employed_for_kind', 'employment_unemployed', 'marital_status_married_or_living_together', 'marital_status_never_married', 'marital_status_widowed_divorced_separated', 'residence_rural', 'residence_urban', 'key', 'iso']\n",
      "Data types: [CategoricalDtype(categories=['Afghanistan', 'Albania', 'Angola', 'Armenia', 'Azerbaijan',\n",
      "                  'Bangladesh', 'Benin', 'Bolivia', 'Burkina Faso', 'Burundi',\n",
      "                  'Cambodia', 'Cameroon', 'Chad', 'Colombia', 'Comoros',\n",
      "                  'Congo', 'Congo Democratic Republic', 'Cote d'Ivoire',\n",
      "                  'Dominican Republic', 'Egypt', 'Eritrea', 'Eswatini',\n",
      "                  'Ethiopia', 'Gabon', 'Gambia', 'Ghana', 'Guatemala',\n",
      "                  'Guinea', 'Guyana', 'Haiti', 'Honduras', 'India',\n",
      "                  'Indonesia', 'Jordan', 'Kenya', 'Kyrgyz Republic', 'Lesotho',\n",
      "                  'Liberia', 'Madagascar', 'Malawi', 'Maldives', 'Mali',\n",
      "                  'Moldova', 'Morocco', 'Mozambique', 'Myanmar', 'Namibia',\n",
      "                  'Nepal', 'Nicaragua', 'Niger', 'Nigeria', 'Pakistan', 'Peru',\n",
      "                  'Philippines', 'Rwanda', 'Sao Tome and Principe', 'Senegal',\n",
      "                  'Sierra Leone', 'South Africa', 'Tajikistan', 'Tanzania',\n",
      "                  'Timor-Leste', 'Togo', 'Turkey', 'Turkmenistan', 'Uganda',\n",
      "                  'Ukraine', 'Yemen', 'Zambia', 'Zimbabwe'],\n",
      ", ordered=False, categories_dtype=object), dtype('O'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('O'), CategoricalDtype(categories=['AFG', 'ALB', 'AGO', 'ARM', 'AZE', 'BGD', 'BEN', 'BOL',\n",
      "                  'BFA', 'BDI', 'KHM', 'CMR', 'TCD', 'COL', 'COM', 'COG',\n",
      "                  'COD', 'CIV', 'DOM', 'EGY', 'ERI', 'SWZ', 'ETH', 'GAB',\n",
      "                  'GMB', 'GHA', 'GTM', 'GIN', 'GUY', 'HTI', 'HND', 'IND',\n",
      "                  'IDN', 'JOR', 'KEN', 'KGZ', 'LSO', 'LBR', 'MDG', 'MWI',\n",
      "                  'MDV', 'MLI', 'MDA', 'MAR', 'MOZ', 'MMR', 'NAM', 'NPL',\n",
      "                  'NIC', 'NER', 'NGA', 'PAK', 'PER', 'PHL', 'RWA', 'STP',\n",
      "                  'SEN', 'SLE', 'ZAF', 'TJK', 'TZA', 'TLS', 'TGO', 'TUR',\n",
      "                  'TKM', 'UGA', 'UKR', 'YEM', 'ZMB', 'ZWE'],\n",
      ", ordered=False, categories_dtype=object)]\n",
      "Missing values: 0\n",
      "\n",
      "--- FREEDOM ---\n",
      "Shape: (165, 6)\n",
      "Columns: ['country', 'region', 'hf_score', 'pf_score', 'ef_score', 'iso']\n",
      "Data types: [CategoricalDtype(categories=['Albania', 'Algeria', 'Angola', 'Argentina', 'Armenia',\n",
      "                  'Australia', 'Austria', 'Azerbaijan', 'Bahamas, The',\n",
      "                  'Bahrain',\n",
      "                  ...\n",
      "                  'Ukraine', 'United Arab Emirates', 'United Kingdom',\n",
      "                  'United States', 'Uruguay', 'Venezuela, RB', 'Vietnam',\n",
      "                  'Yemen, Rep.', 'Zambia', 'Zimbabwe'],\n",
      ", ordered=False, categories_dtype=object), CategoricalDtype(categories=['Caucasus & Central Asia', 'East Asia', 'Eastern Europe',\n",
      "                  'Latin America & the Caribbean',\n",
      "                  'Middle East & North Africa', 'North America', 'Oceania',\n",
      "                  'South Asia', 'Sub-Saharan Africa', 'Western Europe'],\n",
      ", ordered=False, categories_dtype=object), dtype('float64'), dtype('float64'), dtype('float64'), CategoricalDtype(categories=['ALB', 'DZA', 'AGO', 'ARG', 'ARM', 'AUS', 'AUT', 'AZE',\n",
      "                  'BHS', 'BHR',\n",
      "                  ...\n",
      "                  'UKR', 'ARE', 'GBR', 'USA', 'URY', 'VEN', 'VNM', 'YEM',\n",
      "                  'ZMB', 'ZWE'],\n",
      ", ordered=False, categories_dtype=object)]\n",
      "Missing values: 0\n",
      "\n",
      "--- DANGER ---\n",
      "Shape: (50, 9)\n",
      "Columns: ['country', 'wdi', 'wss', 'ih', 'npv', 'ipv', 'ld', 'atv', 'iso']\n",
      "Data types: [dtype('O'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('O')]\n",
      "Missing values: 0\n",
      "\n",
      "--- GDP ---\n",
      "Shape: (259, 3)\n",
      "Columns: ['country', 'iso', 'log_GDP']\n",
      "Data types: [CategoricalDtype(categories=['Afghanistan', 'Africa Eastern and Southern',\n",
      "                  'Africa Western and Central', 'Albania', 'Algeria',\n",
      "                  'American Samoa', 'Andorra', 'Angola', 'Antigua and Barbuda',\n",
      "                  'Arab World',\n",
      "                  ...\n",
      "                  'Uruguay', 'Uzbekistan', 'Vanuatu', 'Venezuela, RB',\n",
      "                  'Vietnam', 'West Bank and Gaza', 'World', 'Yemen, Rep.',\n",
      "                  'Zambia', 'Zimbabwe'],\n",
      ", ordered=False, categories_dtype=object), CategoricalDtype(categories=['ABW', 'AFE', 'AFG', 'AFW', 'AGO', 'ALB', 'AND', 'ARB',\n",
      "                  'ARE', 'ARG',\n",
      "                  ...\n",
      "                  'VEN', 'VNM', 'VUT', 'WLD', 'WSM', 'XKX', 'YEM', 'ZAF',\n",
      "                  'ZMB', 'ZWE'],\n",
      ", ordered=False, categories_dtype=object), dtype('float64')]\n",
      "Missing values: 0\n",
      "\n",
      "--- WAGE_GAP ---\n",
      "Shape: (43, 2)\n",
      "Columns: ['iso', 'gwg_%']\n",
      "Data types: [CategoricalDtype(categories=['AUS', 'AUT', 'BEL', 'BGR', 'CAN', 'CHE', 'COL', 'CRI',\n",
      "                  'CYP', 'CZE', 'DEU', 'DNK', 'ESP', 'EST', 'EU27', 'FIN',\n",
      "                  'FRA', 'GBR', 'GRC', 'HRV', 'HUN', 'IRL', 'ISL', 'ISR',\n",
      "                  'ITA', 'JPN', 'KOR', 'LTU', 'LVA', 'MEX', 'MLT', 'NLD',\n",
      "                  'NOR', 'NZL', 'OECD', 'POL', 'PRT', 'ROU', 'SVK', 'SVN',\n",
      "                  'SWE', 'TUR', 'USA'],\n",
      ", ordered=False, categories_dtype=object), dtype('float64')]\n",
      "Missing values: 0\n",
      "\n",
      "--- UNEMPLOYMENT ---\n",
      "Shape: (1134, 5)\n",
      "Columns: ['country', 'sex', 'age', 'percentage_unemployement', 'iso']\n",
      "Data types: [CategoricalDtype(categories=['Afghanistan', 'Albania', 'Algeria', 'Angola', 'Argentina',\n",
      "                  'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas',\n",
      "                  ...\n",
      "                  'United States', 'United States Virgin Islands', 'Uruguay',\n",
      "                  'Uzbekistan', 'Vanuatu', 'Venezuela, Bolivarian Republic of',\n",
      "                  'Viet Nam', 'Yemen', 'Zambia', 'Zimbabwe'],\n",
      ", ordered=False, categories_dtype=object), CategoricalDtype(categories=['Female', 'Male'], ordered=False, categories_dtype=object), CategoricalDtype(categories=['15-24', '25+', 'Under 15'], ordered=False, categories_dtype=object), dtype('float64'), dtype('O')]\n",
      "Missing values: 0\n",
      "\n",
      "--- GII ---\n",
      "Shape: (195, 12)\n",
      "Columns: ['country', 'human_development', 'gii', 'rank', 'maternal_mortality', 'adolescent_birth_rate', 'seats_parliament', 'f_secondary_educ', 'm_secondary_educ', 'f_labour_force', 'm_labour_force', 'iso']\n",
      "Data types: [dtype('O'), dtype('O'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('O')]\n",
      "Missing values: 133\n",
      "\n",
      "--- LEGAL ---\n",
      "Shape: (127, 3)\n",
      "Columns: ['country', 'percent_leg_equ_achiev_marriage', 'iso']\n",
      "Data types: [CategoricalDtype(categories=['Antigua and Barbuda', 'Argentina', 'Armenia', 'Australia',\n",
      "                  'Austria', 'Azerbaijan', 'Bangladesh', 'Barbados', 'Belarus',\n",
      "                  'Belize',\n",
      "                  ...\n",
      "                  'Uganda', 'Ukraine', 'United Arab Emirates',\n",
      "                  'United Kingdom', 'United States', 'Uruguay', 'Uzbekistan',\n",
      "                  'Vietnam', 'World', 'Zimbabwe'],\n",
      ", ordered=False, categories_dtype=object), dtype('float64'), dtype('O')]\n",
      "Missing values: 8\n",
      "\n",
      "--- PARTNER_VIOLENCE ---\n",
      "Shape: (151, 3)\n",
      "Columns: ['country', 'value', 'iso']\n",
      "Data types: [CategoricalDtype(categories=['Afghanistan', 'Albania', 'Angola', 'Argentina', 'Armenia',\n",
      "                  'Australia', 'Austria', 'Azerbaijan', 'Bangladesh',\n",
      "                  'Belarus',\n",
      "                  ...\n",
      "                  'Ukraine',\n",
      "                  'United Kingdom of Great Britain and Northern Ireland',\n",
      "                  'United Republic of Tanzania', 'United States of America',\n",
      "                  'Uruguay', 'Vanuatu', 'Venezuela (Bolivarian Republic of)',\n",
      "                  'Viet Nam', 'Zambia', 'Zimbabwe'],\n",
      ", ordered=False, categories_dtype=object), dtype('int32'), CategoricalDtype(categories=['AFG', 'ALB', 'AGO', 'ARG', 'ARM', 'AUS', 'AUT', 'AZE',\n",
      "                  'BGD', 'BLR',\n",
      "                  ...\n",
      "                  'UKR', 'GBR', 'TZA', 'USA', 'URY', 'VUT', 'VEN', 'VNM',\n",
      "                  'ZMB', 'ZWE'],\n",
      ", ordered=False, categories_dtype=object)]\n",
      "Missing values: 0\n",
      "\n",
      "--- EQ_LAWS ---\n",
      "Shape: (7, 8)\n",
      "Columns: ['continent', 'employment_discrimination_law', 'equal_remuneration_law', 'maternity_leave', 'domestic_violence_legislation', 'property_rights_equality', 'business_registration_equality', 'iso']\n",
      "Data types: [dtype('O'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('O')]\n",
      "Missing values: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"domestic\": dv_df_pro,\n",
    "    \"vawg\": vawg_df_pro,\n",
    "    \"freedom\": hfi_df_pro,\n",
    "    \"danger\": mdc_df_pro,\n",
    "    \"gdp\": gdp_df_pro,\n",
    "    \"wage_gap\": gwg_df_pro,\n",
    "    \"unemployment\": gud_df_pro,\n",
    "    \"gii\": gii_df_clean,\n",
    "    \"legal\": lf_df_pro,\n",
    "    \"partner_violence\": aip_df_pro,\n",
    "    \"eq_laws\": gel_df_pro\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"--- {name.upper()} ---\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    print(\"Data types:\", df.dtypes.tolist())\n",
    "    print(\"Missing values:\", df.isna().sum().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e342f4",
   "metadata": {},
   "source": [
    "## Saving Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "e74cbc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\domestic.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\vawg.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\freedom.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\danger.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\gdp.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\wage_gap.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\unemployment.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\gii.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\legal.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\partner_violence.csv\n",
      "Saved to: C:\\Users\\black\\Documents\\Ironhack\\final_project\\data\\processed\\eq_laws.csv\n"
     ]
    }
   ],
   "source": [
    "for name, df in datasets.items():\n",
    "    file_path = PROCESSED_DIR / f\"{name}.csv\"\n",
    "    save_df(df, file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ironhack)",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
